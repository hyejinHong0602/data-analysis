{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# -----------------------------------\n",
    "# 학습 데이터, 테스트 데이터의 불러오기\n",
    "# -----------------------------------\n",
    "# 학습 데이터, 테스트 데이터의 불러오기\n",
    "train = pd.read_csv('./train.csv')\n",
    "test = pd.read_csv('./test.csv')\n",
    "\n",
    "# 학습 데이터를 특징과 목적변수로 나누기\n",
    "train_x = train.drop(['Survived'], axis=1)\n",
    "train_y = train['Survived']\n",
    "\n",
    "# 테스트 데이터는 특징만 있으므로, 그대로 사용\n",
    "test_x = test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    1\n",
       "2    1\n",
       "3    1\n",
       "4    0\n",
       "Name: Survived, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------\n",
    "# 특징 추출(피처 엔지니어링)\n",
    "# -----------------------------------\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# 특징 PassengerId를 제거\n",
    "train_x = train_x.drop(['PassengerId'], axis=1)\n",
    "test_x = test_x.drop(['PassengerId'], axis=1)\n",
    "\n",
    "# 특징 [Name, Ticket, Cabin]을 제거\n",
    "train_x = train_x.drop(['Name', 'Ticket', 'Cabin'], axis=1)\n",
    "test_x = test_x.drop(['Name', 'Ticket', 'Cabin'], axis=1)\n",
    "\n",
    "# 범주형 특징에 label encoding 을 적용하여 수치로 변환\n",
    "for c in ['Sex', 'Embarked']:\n",
    "    # 학습 데이터를 기반으로 어떻게 변환할지 최적화\n",
    "    le = LabelEncoder()\n",
    "    le.fit(train_x[c].fillna('NA'))\n",
    "\n",
    "    # 학습 데이터, 테스트 데이터를 변환\n",
    "    train_x[c] = le.transform(train_x[c].fillna('NA'))\n",
    "    test_x[c] = le.transform(test_x[c].fillna('NA'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:12:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------------\n",
    "# 모델 만들기\n",
    "# -----------------------------------\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# 모델 생성 및 학습 데이터를 이용한 모델 학습\n",
    "# model = XGBClassifier(n_estimators=20, random_state=71)\n",
    "model = XGBClassifier(n_estimators=20, random_state=71, use_label_encoder=False)\n",
    "model.fit(train_x, train_y)\n",
    "\n",
    "# 테스트 데이터의 예측 결과를 확률로 출력\n",
    "pred = model.predict_proba(test_x)[:, 1]\n",
    "\n",
    "# 테스트 데이터의 예측 결과를 두개의 값(1,0)으로 변환\n",
    "pred_label = np.where(pred > 0.5, 1, 0)\n",
    "\n",
    "# 제출용 파일 작성\n",
    "submission = pd.DataFrame({'PassengerId': test['PassengerId'], 'Survived': pred_label})\n",
    "submission.to_csv('submission_first.csv', index=False)\n",
    "# score ：0.7799（여기의 실행 결과가 사용자마다 다를 수 있을 가능성이 있습니다.）\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:12:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:12:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:12:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:12:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "logloss: 0.4384, accuracy: 0.8182\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------------\n",
    "# 모델 검증\n",
    "# -----------------------------------\n",
    "from sklearn.metrics import log_loss, accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# 각 fold의 평가 점수를 저장을 위한 빈 리스트 선언\n",
    "scores_accuracy = []\n",
    "scores_logloss = []\n",
    "\n",
    "# 교차 검증(Cross-validation)을 수행\n",
    "# 01 학습 데이터를 4개로 분할\n",
    "# 02 그중 하나를 평가용 데이터셋으로 지정\n",
    "# 03 이후 평가용 데이터의 블록을 하나씩 옆으로 옮겨가며 검증을 수행\n",
    "kf = KFold(n_splits=4, shuffle=True, random_state=71)\n",
    "for tr_idx, va_idx in kf.split(train_x):\n",
    "    # 학습 데이터를 학습 데이터와 평가용 데이터셋으로 분할\n",
    "    tr_x, va_x = train_x.iloc[tr_idx], train_x.iloc[va_idx]\n",
    "    tr_y, va_y = train_y.iloc[tr_idx], train_y.iloc[va_idx]\n",
    "\n",
    "    # 모델 학습을 수행\n",
    "    # model = XGBClassifier(n_estimators=20, random_state=71)\n",
    "    model = XGBClassifier(n_estimators=20, random_state=71, use_label_encoder=False)\n",
    "    model.fit(tr_x, tr_y)\n",
    "\n",
    "    # 평가용 데이터의 예측 결과를 확률로 출력\n",
    "    va_pred = model.predict_proba(va_x)[:, 1]\n",
    "\n",
    "    # 평가용 데이터의 점수를 계산\n",
    "    logloss = log_loss(va_y, va_pred)\n",
    "    accuracy = accuracy_score(va_y, va_pred > 0.5)\n",
    "\n",
    "    # 각 fold의 점수를 저장\n",
    "    scores_logloss.append(logloss)\n",
    "    scores_accuracy.append(accuracy)\n",
    "\n",
    "#각 fold의 점수 평균을 출력.\n",
    "logloss = np.mean(scores_logloss)\n",
    "accuracy = np.mean(scores_accuracy)\n",
    "print(f'logloss: {logloss:.4f}, accuracy: {accuracy:.4f}')\n",
    "# logloss: 0.4270, accuracy: 0.8148（여기의 실행 결과가 사용자마다 다를 수 있을 가능성이 있습니다.）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:12:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:12:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:12:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:12:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:12:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:12:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:12:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:12:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:12:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:12:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:12:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:12:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:12:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:12:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:12:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:12:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:12:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:12:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:12:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:12:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:12:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:12:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:12:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:12:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:12:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:12:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:12:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:12:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:12:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:12:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:12:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:12:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:12:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:12:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:12:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:12:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "max_depth: 3, min_child_weight: 2.0\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------------\n",
    "# 모델 튜닝\n",
    "# -----------------------------------\n",
    "import itertools\n",
    "\n",
    "# 튜닝을 위한 후보 파라미터 값을 준비\n",
    "param_space = {\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'min_child_weight': [1.0, 2.0, 4.0]\n",
    "}\n",
    "\n",
    "# 하이퍼파라미터 값의 조합\n",
    "param_combinations = itertools.product(param_space['max_depth'], param_space['min_child_weight'])\n",
    "\n",
    "# 각 파라미터의 조합(params)과 그에 대한 점수를 보존(scores)하는 빈 리스트\n",
    "params = []\n",
    "scores = []\n",
    "\n",
    "# 각 파라미터 조합별로 교차 검증(Cross-validation)으로 평가를 수행\n",
    "for max_depth, min_child_weight in param_combinations:\n",
    "\n",
    "    score_folds = []\n",
    "    # 교차 검증(Cross-validation)을 수행\n",
    "    # 학습 데이터를 4개로 분할한 후,\n",
    "    # 그중 하나를 평가용 데이터로 삼아 평가. 이를 데이터를 바꾸어 가면서 반복\n",
    "    kf = KFold(n_splits=4, shuffle=True, random_state=123456)\n",
    "    for tr_idx, va_idx in kf.split(train_x):\n",
    "        # 학습 데이터를 학습 데이터와 평가용 데이터로 분할\n",
    "        tr_x, va_x = train_x.iloc[tr_idx], train_x.iloc[va_idx]\n",
    "        tr_y, va_y = train_y.iloc[tr_idx], train_y.iloc[va_idx]\n",
    "\n",
    "        # 모델의 학습을 수행\n",
    "        model = XGBClassifier(n_estimators=20, random_state=71, use_label_encoder=False,\n",
    "                              max_depth=max_depth, min_child_weight=min_child_weight)\n",
    "        model.fit(tr_x, tr_y)\n",
    "\n",
    "        # 검증용 데이터의 점수를 계산한 후 저장\n",
    "        va_pred = model.predict_proba(va_x)[:, 1]\n",
    "        logloss = log_loss(va_y, va_pred)\n",
    "        score_folds.append(logloss)\n",
    "\n",
    "    # 각 fold의 점수 평균을 구함\n",
    "    score_mean = np.mean(score_folds)\n",
    "\n",
    "    # 파라미터를 조합하고 그에 대한 점수를 저장\n",
    "    params.append((max_depth, min_child_weight))\n",
    "    scores.append(score_mean)\n",
    "\n",
    "# 가장 점수가 좋은 것을 베스트 파라미터로 지정\n",
    "best_idx = np.argsort(scores)[0]\n",
    "best_param = params[best_idx]\n",
    "print(f'max_depth: {best_param[0]}, min_child_weight: {best_param[1]}')\n",
    "# max_depth=7, min_child_weight=2.0의 점수가 가장 좋음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# -----------------------------------\n",
    "# 로지스틱 회귀용 특징 작성\n",
    "# -----------------------------------\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# 원본 데이터를 복사하기\n",
    "train_x2 = train.drop(['Survived'], axis=1)\n",
    "test_x2 = test.copy()\n",
    "\n",
    "# 특징 PassengerId를 제거\n",
    "train_x2 = train_x2.drop(['PassengerId'], axis=1)\n",
    "test_x2 = test_x2.drop(['PassengerId'], axis=1)\n",
    "\n",
    "# 특징 [Name, Ticket, Cabin]을 제거\n",
    "train_x2 = train_x2.drop(['Name', 'Ticket', 'Cabin'], axis=1)\n",
    "test_x2 = test_x2.drop(['Name', 'Ticket', 'Cabin'], axis=1)\n",
    "\n",
    "# 원핫 인코딩(one hot encoding)을 수행\n",
    "cat_cols = ['Sex', 'Embarked', 'Pclass']\n",
    "ohe = OneHotEncoder(categories='auto', sparse=False)\n",
    "ohe.fit(train_x2[cat_cols].fillna('NA'))\n",
    "\n",
    "# 원핫 인코딩의 더미 변수의 열이름을 작성\n",
    "ohe_columns = []\n",
    "for i, c in enumerate(cat_cols):\n",
    "    ohe_columns += [f'{c}_{v}' for v in ohe.categories_[i]]\n",
    "\n",
    "# 원핫 인코딩에 의한 변환을 수행\n",
    "ohe_train_x2 = pd.DataFrame(ohe.transform(train_x2[cat_cols].fillna('NA')), columns=ohe_columns)\n",
    "ohe_test_x2 = pd.DataFrame(ohe.transform(test_x2[cat_cols].fillna('NA')), columns=ohe_columns)\n",
    "\n",
    "# 원핫 인코딩이 수행 후, 원래 특징를 제거\n",
    "train_x2 = train_x2.drop(cat_cols, axis=1)\n",
    "test_x2 = test_x2.drop(cat_cols, axis=1)\n",
    "\n",
    "# 원핫 인코딩을 수행된 특징를 결합\n",
    "train_x2 = pd.concat([train_x2, ohe_train_x2], axis=1)\n",
    "test_x2 = pd.concat([test_x2, ohe_test_x2], axis=1)\n",
    "\n",
    "# 수치변수의 결측치를 학습 데이터의 평균으로 채우기\n",
    "num_cols = ['Age', 'SibSp', 'Parch', 'Fare']\n",
    "for col in num_cols:\n",
    "    train_x2[col].fillna(train_x2[col].mean(), inplace=True)\n",
    "    test_x2[col].fillna(train_x2[col].mean(), inplace=True)\n",
    "\n",
    "# 특징Fare를 로그 변환을 수행\n",
    "train_x2['Fare'] = np.log1p(train_x2['Fare'])\n",
    "test_x2['Fare'] = np.log1p(test_x2['Fare'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:12:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# -----------------------------------\n",
    "# 앙상블(ensemble)\n",
    "# -----------------------------------\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# xgboost 모델\n",
    "model_xgb = XGBClassifier(n_estimators=20, random_state=71, use_label_encoder=False)\n",
    "model_xgb.fit(train_x, train_y)\n",
    "pred_xgb = model_xgb.predict_proba(test_x)[:, 1]\n",
    "\n",
    "# 로지스틱 회귀 모델\n",
    "# xgboost 모델과는 다른 특징을 넣어야 하므로 train_x2, test_x2를 생성\n",
    "model_lr = LogisticRegression(solver='lbfgs', max_iter=300)\n",
    "model_lr.fit(train_x2, train_y)\n",
    "pred_lr = model_lr.predict_proba(test_x2)[:, 1]\n",
    "\n",
    "# 예측 결과의 가중 평균 구하기\n",
    "pred = pred_xgb * 0.8 + pred_lr * 0.2\n",
    "pred_label = np.where(pred > 0.5, 1, 0)\n",
    "\n",
    "# 제출용 파일 작성\n",
    "submission = pd.DataFrame({'PassengerId': test['PassengerId'], 'Survived': pred_label})\n",
    "submission.to_csv('submission_first_ensemble.csv', index=False)\n",
    "# score ：0.7799（여기의 실행 결과가 사용자마다 다를 수 있을 가능성이 있습니다.）"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
